---
title: "MATH513 Practical Presentation"
author: "10570155, 10696253, 10701983"
date: "10/12/2020"
output:
  beamer_presentation: 
    theme: Boadilla
    colortheme: beaver
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# IMPORT DEPENDENCIES -------------------------------------------------------------------------------------------------------
libs <- c('readr', 'dplyr', 'tidyverse', 'tidyr', 'tidytext', 'modelr', 'stringr', 'rtweet', 'ggplot2', 'ggthemes','scales', 'knitr', 'rworldmap', 'lubridate')
invisible(lapply(libs, library, character.only = TRUE))

# IMPORT DATA ---------------------------------------------------------------------------------------------------------------
tweets <- read_csv("../data/cleaned-tweets.csv") #Load in tweets from the csv file.
users <- read_csv("../data/cleaned-users.csv")

```


## Introduction

<!--- 

OVERVIEW

  Speaker notes are kept in comments to hide from presentation unless the comment is in a code chunk which will be in place to keep a track of the code execution and purpose.
  
  Code requires you to have the csv data set that is available from the following GitHub repository: https://github.com/Mauzey/MATH513-Group-Work.
  
  Extraction code and most of the cleaning/feature engineering code has been left in the GitHub and not embedded here as per discussion with Luciana to avoid overwhelming the rMarkdown file. 
  
-->


<!--- SPEAKER NOTES - WILL

  Samsung and Apple were chosen as our competing businesses due to the recent release of their flagship phones, the S20FE and iPhone12. This meant we would have access to sufficient relevant data on Twitter to perform analysis on.

  We chose to gather some extra tweets relating to the S20 to give us some comparable information for sentiment analysis and to determine if there was any improvement in sentiment from the S20 to the S20FE from the public. 

  We utilised RStudio in combination with the rTweet package to extra and analyse the data from the Twitter Developer API

  To allow us to work professionally and on various parts of the project as a group we decided to break up the code into sections and utilise GitHub to keep a track on the project.

--->

- Samsung and Apple
- Flagship phones chosen
  + S20FE
  + iPhone12
  + S20 
  
**Tools Utilised**

- Rstudio
- RTweet
- Twitter Developer API
- GitHub

```{r Logos, echo=FALSE, fig.align="center", fig.cap="", fig.show='hold', out.width="15%"}
knitr::include_graphics(c("./Images/Logos/apple_logo.png", "./Images/Logos/samsung_logo.jpg", "./Images/Logos/rstudio_logo.png", "./Images/Logos/twitter_logo.png"))
```

<!--- End of Slide 01 ------------------------------------------------------------------------------------------------------>





<!--- Slide 02 ------------------------------------------------------------------------------------------------------------->

## Research

<!--- SPEAKER NOTES: - WILL
  
  Twitter provides its data through a number of APIs and after the Cambridge Analytica 'data breach', is one of the few social media platforms that has not limited the data provided through APIs, according to Dr. Wasim Ahmed from Newcastle University (2019).
  
  Twitter data can provide insights into the general public's opinions and combined with the openness and the generous rate limiting of Twitter’s API, it can produce powerful results. (Michelle Young Chat Bots Life.com, 2017)

  For our hastags, we looked to the Samsung Mobile page and identified that the hastags #GalaxyS20 and #GalaxyS20FE were the offical hashtags used by Samsung.
  
  We then looked for the same information from Apple but found that since the Twitter account was hacked in July (15h July 2020), Apple have not been keeping tweets on their Twitter page. (Swider, Matt (2020), TechRadar - https://www.techradar.com/news/twitter-hack-2020).
  
  We decided to look to the CEO of Apple, Tim Cook, as we thought he would most likely be using the offical hashtag as deemed by Apple's marketing team, which led us to the hashtag #iPhone12.
  
  We came to the conclusion that it was better to use hashtags instead of pulling data from profiles, either business or individual. This was to ensure we would get a wide range of opinions for a fairer analysis of the publics sentiment.

--->

<!--- EXTRA NOTES (Cut from speaker notes to save time):

  We performed some sample searches of other hashtags like S20 and S20FE using the advanced Twitter search, on the website, to determine how relevant the hashtag was.
  
  We went through search results and examined the difference between the date of the latest tweet and the date of the 25th tweet in the list. This identified whether a hashatag was being used by the public and this further supported our findings that the hastags iphone12, samsungs20 and samungs20fe were the best to pull data.

--->

**Choosing Twitter for Analysis**

- Open API Access compared to others
- Almost all data is public
- Advanced filtering and queries
- Generous Rate limiting

**Hashtags**

- @SamsungMobile - [https://twitter.com/SamsungMobile](https://twitter.com/SamsungMobile)
- @Apple - [https://twitter.com/Apple](https://twitter.com/Apple) 
- @tim_cook - [https://twitter.com/tim_cook](https://twitter.com/tim_cook)

<!--- End of Slide 02 ------------------------------------------------------------------------------------------------------>





<!--- Slide 03 ------------------------------------------------------------------------------------------------------------->

## Data Cleaning and Feature Engineering

<!--- SPEAKER NOTES - Alex

  - We removed duplicate entries for both the tweet and user data
    - Duplicate tweets were collected due to overlapping data collection periods
      - We started with about 110,000 tweets, and ended up with roughly 74,000 tweets
      
    - Duplicate users were collected because one user can post many tweets
      - Again, we started with about 110,000 users (one for each tweet), that went down to roughly 35,000 unique users
  
  - We then stripped the tweet text and user bios of:
    - Links
    - Hash-tags
    - Emojis
    - User mentions
  
  - Users were marked as potential bots based on:
    - Whether the source of their tweets identified them as a bot through the use of keywords
    - ...and whether the user's bio identified them as a bot, this also used keywords

  - The raw user locations varied because twitter allows custom locations (such as 'on a mountain' or 'earth'):
    - We used the 'country code' package to extract countries in order to make them usable in analysis and had 25% of tweets with a location
    
  - Tweets were marked as potential spam based on:
    - Whether the tweet text identified it as spam, through the use of keywords
    - ...and whether the author of the tweet had been previously marked as a bot
  
  - We had to manually extract the hash-tags from the tweet text due to an issue with rtweet
  
  - We extracted product features from each of the tweet's text due to a glitch in rtweet
    - These features were: The product's Display, Camera, Battery, Price, and 5G Capabilities
  
#### REWRITE
    - Finally, sentiment score was calculated for each tweet.

--->

**Data Cleaning**

- Duplicate tweet and user observations were removed
- Tweet text and user bios were cleaned
  + Removed links, hash-tags, emojis, and user mentions

**Feature Engineering**

- Users were marked as potential bots
- User country was extracted from the location of their profile
- Tweets were marked as potential spam
- Hash-tags were extracted from the tweet text
- Product features were extracted from the tweet text
  + Display, Battery, Camera, Price, and 5G Capability
- An overall sentiment score was calculated for each tweet

<!--- End of Slide 03 ------------------------------------------------------------------------------------------------------>






<!--- Slide 04 ------------------------------------------------------------------------------------------------------------->

## Summary of Collected Data

<!--- SPEAKER NOTES- ALEX

  - After data cleaning, we were left with about 74,000 tweets and 5 extracted features
  
  - Table 1 shows a summary of the collected tweet data grouped by product:
  
    - There were less tweets for the Galaxy S20 than the S20 FE and iPhone 12.
      - This is due to the constraints imposed by the Twitter API rate limits
    
    - 15-20% of the S20 FE and iPhone12 tweets were marked as spam, compared to the 3% for the S20
      - This is perhaps due to the spammers focusing their efforts on newer, more relevant products in order to reach
        a wider audience
    
    - Only 7% of iPhone12 tweets contained mentions of the chosen features, compared to roughly 20% for the S20 and S20 FE
  
  - Table 2 shows a summary of the user data:
  
    - There were about 35,000 unique users, from 163 identified countries
    
    - Less than 1% of these users were marked as bots. The actual amount being 155
    
--->

```{r Overview of Data Extracted, echo=FALSE, message=FALSE, warning=FALSE}

total_tweets <- nrow(tweets)

tweets_summary <- tweets %>%
  group_by(product) %>%  # Group by product
  summarise(n_tweets = length(status_id),  # Number of tweets
            percent_spam = percent(length(which(potential_spam == T))/n_tweets),  # % spam tweets
            percent_features = percent(length(which(!is.na(mentioned_features)))/n_tweets)  # % of tweets with mentioned features
  ) %>%
  rename('Product' = product, 'Number of Tweets' = n_tweets,
         '% Spam Tweets' = percent_spam,'% Feature Tweets' = percent_features)

users_summary <- users %>%
  summarise(n_users = length(user_id),  # Number of unique users
            percent_bots = '>1%',  # % of bot users (actual value = 0.00442)
            n_countries = length(unique(country))  # Number of unique countries
  ) %>%
  rename('Number of Users' = n_users, '% Bot Users' = percent_bots, 'Unique Countries' = n_countries)
```

**Total Tweets:** `r total_tweets` after data cleaning

**Total Features:** `5 (Display, Battery, Camera, Price, and 5G)`

`r kable(tweets_summary, caption = "Summary of Tweet Data")`

`r kable(users_summary, caption = "Summary of User Data")`

<!--- End of Slide 04 ------------------------------------------------------------------------------------------------------>





<!--- Slide 05 ------------------------------------------------------------------------------------------------------------->

## Time Periods for Data Collection

<!--- SPEAKER NOTES - Will

  The normal twitter function allowed us to pull data from the last 6-9 days. We decided that just after the release date of the phones would be the best time to examine the public's opinion.

  Due to the limitations of the general search, we utilised the full archive premium feature to pull tweets relating to the S20, seen here in red. 
  
  However, there was a mistake that led to the tweets being pulled a little earlier than the release date as seen by the red vertical line on the graph. 
  
  We leanrt from this and corrected our code and pulled as much data as we could for the other two phone using the premium 30 day function.
  
  The 30 day limitation meant that the tweets we pulled are about 3 weeks after the release date for the S20FE, seen in green and 1 week after the iPhone seen in blue.
  
  From the graph, you can see that we managed to gather a reasonable amount of tweets over the month of November for both these phones.

--->

```{r echo=FALSE, echo=FALSE, warning=FALSE, message=FALSE, fig.width=8, fig.height=4.5}
tweets$product <- as.factor(tweets$product)  # Factorize product column

 tweets %>% group_by(product, is_retweet) %>%
  ts_plot('days', trim = 1) +
  labs(x = NULL, y = NULL,
       title = "Frequency of Twitter Statuses",
       subtitle = "Twitter status counts aggregated using 1-day intervals",
       caption = "Source: Data collected from Twitter's REST API via rtweet",
       color = "Product",
       linetype = "Retweet") +
  theme_bw() +
  theme(plot.title = element_text(face = 'bold'),
        strip.text.y = element_blank()) + 
  geom_vline(xintercept = as.POSIXct(as.Date("2020-03-06")), colour = "turquoise") +
  geom_vline(xintercept = as.POSIXct(as.Date("2020-10-02")), colour = "mediumpurple1") +
  geom_vline(xintercept = as.POSIXct(as.Date("2020-10-23")), colour = "lightgoldenrod3") +
  facet_grid(product ~ .) +
  scale_color_manual(values = c("Galaxy S20" = "turquoise",
                               "Galaxy S20 FE" = "mediumpurple1",
                               "iPhone12" = "lightgoldenrod3"))
```

<!--- End of Slide 05 ------------------------------------------------------------------------------------------------------>





<!--- Slide 06 ------------------------------------------------------------------------------------------------------------->

## Results - Sentiment Analysis - All Tweets

<!-- SPEAKER NOTES - Tania

  We decided to perform sentiment analysis both generally for each model and 
  for 5 most often mentioned features: Camera, 5G, Display, Price and Battery.

  For sentiment analysis, we used the 'sentimentr' package which calculates average sentiment for a group of sentences instead of calculating sentiment scores for individual words. This was more suitable for our analysis since we're analysing the feedback (in form of tweets, each tweet consists of 1 or more whole sentences) on each feature for each of the 3 products.

  This slide demonstrates the overall sentiment for each product. 

  As you can see, the Galaxy S20FE, seen in purple, has the highest mean sentiment.

  The idea behind the release of the S20FE is that Samsung took their customer's feedback into consideration and implemented some changes for features like display, price, battery. 
  
  This can be seen by the S20FE having a higher mean sentiment than the S20 seen here in turquoise.

-->

```{r include=FALSE}
# Calculate the mean sentiment for each product
mean_sentiment <- tweets %>% 
                            group_by(product) %>%
                            summarize(mean_sentiment = signif(mean(avg_sentiment), 6))  
```

```{r echo=FALSE, warning=FALSE, message=FALSE, fig.width=8, fig.height=5}
# Plot the distribution of sentiment for tweets for all models
tweets %>%
  filter(potential_spam == F) %>%
  ggplot(aes(x = avg_sentiment, fill = product)) + theme_minimal() +
    geom_histogram(aes(y = ..density..), colour = 'black') +
    geom_vline(data = filter(mean_sentiment, product == 'iPhone12'), aes(xintercept = mean_sentiment)) +
    geom_vline(data = filter(mean_sentiment, product == 'Galaxy S20 FE'), aes(xintercept = mean_sentiment)) +
  geom_vline(data = filter(mean_sentiment, product == 'Galaxy S20'), aes(xintercept = mean_sentiment)) +
    # Mean sentiment text for each product
    geom_text(data = filter(mean_sentiment, product == 'iPhone12'),
              aes(x = mean_sentiment, y = Inf, label = paste('Mean: ', mean_sentiment), vjust = 2, hjust = -0.1)) +
    geom_text(data = filter(mean_sentiment, product == 'Galaxy S20 FE'),
              aes(x = mean_sentiment, y = Inf, label = paste('Mean: ', mean_sentiment), vjust = 2, hjust = -0.1)) +
    geom_text(data = filter(mean_sentiment, product == 'Galaxy S20'),
            aes(x = mean_sentiment, y = Inf, label = paste('Mean: ', mean_sentiment), vjust = 2, hjust = -0.1)) +
  
    facet_grid(product ~ .) +
    scale_fill_manual(values = c('iPhone12' = 'lightgoldenrod3', 
                                 'Galaxy S20 FE' = 'mediumpurple1',
                                 'Galaxy S20' = 'turquoise')) +
    labs(x = "Sentiment Score", y = "Density",
         title = "Distribution of Sentiment Scores Across Tweets Related to All the Models",
         caption = "Source: Data collected from Twitter's REST API via rtweet",
         fill = "Product: ") +
    theme(legend.position = 'bottom',
          plot.title = element_text(face = 'bold'),
          strip.text.y = element_blank())
```

<!--- End of Slide 06 ------------------------------------------------------------------------------------------------------>





<!--- Slide 07 ------------------------------------------------------------------------------------------------------------->

## Results - Sentiment Analysis - Features

<!--- SPEAKER NOTES - Tania

!!Overview of sentiment analysis##


Samsung's improvement of particular features which gathered feedback from customers who purchased S20 and S20 Ultra can be clearly seen from the following boxplots that demonstrate sentiments for products of both Samsung and Apple grouped by features. 
We can observe that the sentiment for all the S20 FE's features except for camera, is higher than of S20, not mentioning that it's higher than of iphone12 in display, price and battery categories.
Which is again pretty logical considering that Samsung equipps their new flagships with displays which have refresh rate of 120 Hz and 140 Hz.

--->

```{r include=FALSE}
# SENTIMENT ANALYSIS - Product Features -------------------------------------------------------------------------------------
#For features analysis we'll be using a different package to the lectures called "sentimentr"

#Find more info about it here:https://towardsdatascience.com/sentiment-analysis-in-r-good-vs-not-good-handling-negations-2404ec9ff2ae

# “sentimentr attempts to take into account valence shifters # (i.e., negators, amplifiers (intensifiers), de-amplifiers (downtoners), # and adversative conjunctions) while maintaining speed. Simply put, # sentimentr is an augmented dictionary lookup.”

# Compute overall sentiment score for each tweet using sentimentr

# Extract relevant information
feature_sentiment_data <- select(tweets, product, mentioned_features, avg_sentiment, sd_sentiment)

# Separate 'mentioned_features' column
feature_sentiment_data <- separate(feature_sentiment_data, col = mentioned_features, into = paste0('feature', 1:5), sep = ', ')

# Pivot feature columns
feature_sentiment <- pivot_longer(feature_sentiment_data, cols = names(feature_sentiment_data)[which(grepl('feature', names(feature_sentiment_data)))])

# Remove NAs and whitespace
feature_sentiment <- feature_sentiment %>%
  mutate(value = trimws(value)) %>% filter(!is.na(value))

feature_sentiment_stat <- feature_sentiment %>% 
  group_by(product, value) %>% 
  summarise(mean_sentiment = mean(avg_sentiment),
            sum_sentiment = sum(avg_sentiment))
```

```{r echo=FALSE, echo=FALSE, warning=FALSE, message=FALSE, fig.width=8, fig.height=4.5}
#BOXPLOT
feature_sentiment %>% 
  group_by(product) %>%
  ggplot(aes(x = product, y = avg_sentiment, color = product)) +
  geom_hline(yintercept = 0)+
  geom_boxplot() +
  facet_wrap(. ~ value) +
  theme_bw() +
  scale_color_manual(values = c("iPhone12" = "lightgoldenrod3", 
                               "Galaxy S20" = "turquoise",
                               "Galaxy S20 FE" = "mediumpurple1"),) +
  scale_y_continuous(name = "Sentiment Score") +
  theme(axis.title.x=element_blank(), 
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) +
  labs(title = "Sentiment Score of 5 Features for Each of the Phone Models",
       color = "Phone Model")

```

<!--- End of Slide 07 ------------------------------------------------------------------------------------------------------>



<!--- Slide 08 ------------------------------------------------------------------------------------------------------------->
## Results - Global Sentiment By Product

<!-- SPEAKER NOTES - Alex

  This analysis shows us three main things:
    that our data set may be too small to cover the sentiment globally as evidenced by the white regions seen on the maps

    where the colours are lighter we may need to improve marketing and brand image
    
    where there are darker areas for competitors, extra attention should be taken in those regions to improve brand awareness and public sentiment   

-->

```{r include=FALSE}

# Get the 'user_id' and 'country' of users with valid country values
geo_users <- users %>%
  filter(potential_bot == F & !is.na(country)) %>%
  select(user_id, country)

# Get 'avg_sentiment' and 'product' of tweets posted by users with valid country values
geo_tweets <- tweets %>%
  filter(potential_spam == F & user_id %in% geo_users$user_id) %>%
  select(user_id, product, avg_sentiment)

# Merge the data frames
geo_sentiment <- merge(geo_users, geo_tweets, by = 'user_id')

# Join data referenced by country codes to an internal map
iPhone12_matched <- geo_sentiment %>%
  filter(product == 'iPhone12') %>%
  joinCountryData2Map(joinCode = 'NAME', nameJoinColumn = 'country')

# Join data referenced by country codes to an internal map
S20FE_matched <- geo_sentiment %>%
  filter(product == 'Galaxy S20 FE') %>%
  joinCountryData2Map(joinCode = 'NAME', nameJoinColumn = 'country')

# Join data referenced by country codes to an internal map
S20_matched <- geo_sentiment %>%
  filter(product == 'Galaxy S20') %>%
  joinCountryData2Map(joinCode = 'NAME', nameJoinColumn = 'country')

```

```{r echo=FALSE, warning=FALSE, message=FALSE, fig.align="center", fig.cap="", fig.show='hold', out.width='45%'}

# Plot the average sentiment for tweets regarding the iPhone12, for each country
mapCountryData(iPhone12_matched,
               mapTitle = "iPhone12 Sentiment by Country",
               borderCol = 'gray40',
               colourPalette = c('lightgoldenrod', 'goldenrod2', 'darkgoldenrod4'),
               nameColumnToPlot = 'avg_sentiment', catMethod = 'pretty')

# Plot the average sentiment for tweets regarding the S20 FE, for each country
mapCountryData(S20FE_matched,
               mapTitle = "Galaxy S20 FE Sentiment by Country",
               borderCol = 'gray40',
               colourPalette = c('thistle', 'mediumpurple2', 'purple4'),
               nameColumnToPlot = 'avg_sentiment', catMethod = 'pretty')

```

```{r echo=FALSE, warning=FALSE, message=FALSE, out.width='45%', fig.align='center'}

# Plot the average sentiment for tweets regarding the S20, for each country
mapCountryData(S20_matched,
               mapTitle = "Galaxy S20 Sentiment by Country",
               borderCol = 'gray40',
               colourPalette = c('paleturquoise', 'mediumturquoise', 'turquoise4'),
               nameColumnToPlot = 'avg_sentiment', catMethod = 'pretty')

```

<!--- End of Slide 08 ------------------------------------------------------------------------------------------------------------->





<!--- Slide 09 ------------------------------------------------------------------------------------------------------------->
## Statistical Test - T-Test

<!--- SPEAKER NOTES - Tania

  We can run the t-test when the groups of samples being compared, are normally distributed and when the variances of the groups are equal.

  This can be checked using Shapiro-Wilk's test. The test should be performed on sentiment values for tweets related to each model we're analysing, regardless of whether it's related to any feature or not.

  Since our data set is too large, over 5,000 entries, we performed an Anderson-Darling's test and Kolmogorov-Smirnov test since these test do not have an entry limitiation .
 
  P values for both tests were less then 0.05 which confirms numerically that our data is not normally distributed.

  This is demonstrated by the density plots seen on the slide.
  
  Hence, the t-test is not applicable with this data set.

--->

```{r echo=FALSE, warning=FALSE, message=FALSE, fig.width=8, fig.height=4.5} 
feature_sentiment_data %>%
  ggplot(aes(x=avg_sentiment, group=product, fill=product)) +
  geom_density(adjust=1.5, alpha = .9) +
  theme_bw() +
  facet_wrap(~product) +
  scale_fill_manual(values = c("Galaxy S20" = "turquoise",
                               "Galaxy S20 FE" = "mediumpurple1",
                               "iPhone12" = "lightgoldenrod3")) +
  theme(
    legend.position="none",
    panel.spacing = unit(0.1, "lines"),
    axis.ticks.x=element_blank()
  ) +
  labs(x = "Average Sentiment",
       y = "Density",
       title = "Density Plots for Overall Sentiments of 3 Products")
```

<!--- End of Slide 09 ------------------------------------------------------------------------------------------------------>





<!--- Additional Slides??

SLIDE START

  ##STOCK PRICE VS SENTIMENT

    REASON FOR REMOVAL
      Needed to be cut to save time and slide numbers

    SPEAKER NOTES
      We wanted to determine if there was a correlation between the stock price and the current sentiment of the public's opinion on Twitter.
      We decided to use a regression analysis to determine this and see if we could predict future stock price based on the current sentiment.7

    SLIDE INFO
      - Regression analysis used
      - P value = 

      !INSERT CODE CHUNK HERE

END OF SLIDE


SLIDE START

  ##WORD FREQUENCY 

    REASON FOR REMOVAL
      Needed to be cut to save time and slide numbers

    SPEAKER NOTES
      We wanted to identify the most commonly used words to BLAH BLAH BLAH

    SLIDE INFO
      - blah
      - blah

    CODE:
      # Filter out spam
      tweets_no_spam <- tweets %>% filter(potential_spam == F)

      extract_words <- function(data) {
        return(data %>%
                select(stripped_text) %>%
                mutate(tweet_number = row_number()) %>%
                unnest_tokens(word, stripped_text)
        )
      }
      iPhone12_words<- extract_words(tweets_no_spam %>% filter(product == 'Galaxy S20'))
      S20_words <- extract_words(tweets_no_spam %>% filter(product == 'Galaxy S20 FE'))
      S20FE_words <- extract_words(tweets_no_spam %>% filter(product == 'iPhone12'))
      rm(tweets_no_spam, extract_words)  # Remove vars from memory to keep the environment tidy

      # Remove stop words
      data('stop_words')
      iPhone12_words <- iPhone12_words %>% anti_join(stop_words)
      S20_words <- S20_words %>% anti_join(stop_words)
      S20FE_words <- S20FE_words %>% anti_join(stop_words)
      rm(stop_words)  # Remove vars from memory to keep the environment tidy

      # Remove custom stop words
      custom_stop_words <- data.frame(word = c('iphone12', 'iphone', 'apple', '12', 'iphone12pro', 'iphone12promax', 'max', 'min',
                                              'iphone12mini', 'series', 'ios', 'tim_cook', 'uf449', '5544', 'uf525uf525uf525',
                                              'tgfamilyuf64whats', 'stevewoz', '18iphone12', 'timcook', 'ios14', 'pro', 'appleevent',
                                              'id', 'mini', 'phone', 'amazon', 'pick', 'buy', 'shop', 'iphone11', '20',
                                              'appleiphone12', '11', 'free', 'cashback', 'limited', '0001f525', 'giveaway', 'amp',
                                              'bauxyvcr2z', 'fe0f', '393c', '3e32', '0001f449', '0001f64c', '2063', '0001f64f', 'win',
                                              '5', '4', '3', '1', '20b9', '2764', '18', '0001f447', '2796', 'pqsilf3aj0',
                                              'galaxys20', 'galaxy', 'samsung', 's20', 'di', 'ini', 'ultra', 'indonesia', 'pake',
                                              'uf60dsemua', 'timur', 'kok', 'java', 'djambil', 'bukan', 'bondowoso', 'samsungmobilesa',
                                              'expressoshow', 'galaxys20ultra', 'pre', 'uf32fget', 'introducing', 'renders',
                                              'samsungindia', 'official', 'smartphone', 'unpacked2020', 'galaxys20fe', 'phone',
                                              'swiss', 'jawa', 'diambil', 'galaxys20plus', 'mobile', 'galaxys20fultra5g', 'uf60d',
                                              'samsungevent', 'fe', '2020', 'samsunggalaxy', 'unpacked', 'galaxyzflip', 'day', 'check',
                                              'galaxyunpacked', 'leaked', 'de', 'en', 'samsungmobile', '0001f60d', '0001f49c',
                                              '0001f31f', 'contestalert', 'season', 'mintknow', 'btsus', 'moreu', '0001f4b0',
                                              'withugalaxys20feuin', 'jiminukeeps', 'bts', 'galaxys20fesuperfan', 'withgalaxy', 'fe',
                                              'galaxybuds', 'madeforfans', 's20fecamerafan', 'uf49a', 'teamgalaxy', 'galaxyxbts',
                                              '0001f49a', '3e30', '613c', '15', 'semua', 'invebuybmf', 'winner', 'san', 'francisco',
                                              'makes', 'learn', 'apply', 'wfvkmdrti2', 'active2', 'tlch6y0bsp', '30x', 'buds', '0e2d',
                                              '0001f48e', '3x', '383c', 'foto', '0001f499', 'india', 'retweet', 'password', 'usdt',
                                              '_cook', 'newly', '_problem', '0e01', '2', '0001f3fb', 'variant', 'unlock', 'locked',
                                              'reset', 'recovery', 'passcode', 'review', 'launched', 'past', 'time', 'join', 'drop',
                                              'pair', 'w7gnpkkvxi', 'shout', '0e32', 'nov', 'collection', 'winter', 'draw', 'dec',
                                              '3kwjjkvz8o', '2744', '4pm', '27', '0001f606', 'vip', '23f0', '58', '3am', '88', '26c4',
                                              'utc', 'tmsvspi6pw', 'okb', '50,000', '6000', 'gt', 'black', '0001f4f1', 'ft', 'cosmo',
                                              '0001f92f', 'blue', 'ares', 'unboxing', 'blason', 'fwn7ozovs7', '0001f6a8', 'follow',
                                              'devices', 'isn', 'link', '10', 'rt', 'friday', 'store', 'close', 'space', 'glow',
                                              'formats', 'grade', 'mode', 'cloud', 'butterfly\'s'))
      iPhone12_words <- iPhone12_words %>% anti_join(custom_stop_words)
      S20_words <- S20_words %>% anti_join(custom_stop_words)
      S20FE_words <- S20FE_words %>% anti_join(custom_stop_words)

      rm(custom_stop_words, word)  # Remove vars from memory to keep the environment tidy

     ----------------------------------------

      # Plot most frequent words in iPhone 12 tweets
      iPhone12_words %>%
        count(word, sort = T) %>%
        head(30) %>%
        mutate(word = reorder(word, n)) %>%
        ggplot(aes(x = word, y = n)) + theme_minimal() + coord_flip() +
          geom_col(fill = 'lightgoldenrod3', colour = 'darkgoldenrod4') +
          labs(x = "Unique Words", y = "Frequency",
              title = "Top 30 Most Popular Words in iPhone12 Tweets") +
          theme(axis.title = element_text(face = 'bold'),
                axis.text.y = element_text(size = 12))
      
      # Plot most frequent words in Galaxy S20 tweets
      S20_words %>%
        count(word, sort = T) %>%
        head(30) %>%
        mutate(word = reorder(word, n)) %>%
        ggplot(aes(x = word, y = n)) + theme_minimal() + coord_flip() +
          geom_col(fill = 'turquoise', colour = 'turquoise4') +
          labs(x = "Unique Words", y = "Frequency",
              title = "Top 30 Most Popular Words in Galaxy S20 Tweets") +
          theme(axis.title = element_text(face = 'bold'),
                axis.text.y = element_text(size = 12))


      # Plot most frequent words in Galaxy S20 FE tweets
      S20FE_words %>%
        count(word, sort = T) %>%
        head(30) %>%
        mutate(word = reorder(word, n)) %>%
        ggplot(aes(x = word, y = n)) + theme_minimal() + coord_flip() +
          geom_col(fill = 'mediumpurple1', colour = 'mediumpurple4') +
          labs(x = "Unique Words", y = "Frequency",
              title = "Top 30 Most Popular Words in Galaxy S20 FE Tweets") +
          theme(axis.title = element_text(face = 'bold'),
                axis.text.y = element_text(size = 12))
END OF SLIDE

SLIDE START

  ##NEGATIVE AND POSITIVE WORDS OF EACH PRODUCT

    REASON FOR REMOVAL
      Needed to be cut to save time and slide numbers

    SPEAKER NOTES
      BLAH BLAH BLAH

    SLIDE INFO
      - blah
      - blah

    CODE:
      # Get sentiment scores for iPhone12 words
      iPhone12_bing_count <- iPhone12_words %>%
        inner_join(sentiments %>% filter(sentiments$word != 'matte')) %>%
        count(word, sentiment, sort = T) %>%
        mutate(word = reorder(word, n))

      # Plot sentiment scores for iPhone12 words
      iPhone12_bing_count %>% group_by(sentiment) %>%
        top_n(10) %>% ungroup() %>%
        ggplot(aes(x = word, y = n, fill = sentiment)) + theme_minimal() + coord_flip() +
          geom_col(show.legend = F) +
          facet_wrap(~ sentiment, scales = 'free_y') +
          labs(x = NULL, y = "Sentiment",
              title = "Most Common Positive and Negative Words in iPhone12 Tweets") +
          theme(axis.text = element_text(size = 11, colour = 'black'),
                axis.title = element_text(size = 11, colour = 'black'),
                title = element_text(size = 12))

      # Get sentiment scores for Galaxy S20 words
      S20_bing_count <- S20_words %>%
        inner_join(sentiments) %>%
        count(word, sentiment, sort = T) %>%
        mutate(word = reorder(word, n))

      # Plot sentiment scores for Galaxy S20 words
      S20_bing_count %>% group_by(sentiment) %>%
        top_n(10) %>% ungroup() %>%
        ggplot(aes(x = word, y = n, fill = sentiment)) + theme_minimal() + coord_flip() +
          geom_col(show.legend = F) +
          facet_wrap(~ sentiment, scales = 'free_y') +
          labs(x = NULL, y = "Sentiment",
              title = "Most Common Positive and Negative Words in Galaxy S20 Tweets") +
          theme(axis.text = element_text(size = 11, colour = 'black'),
                axis.title = element_text(size = 11, colour = 'black'),
                title = element_text(size = 12))

      # Get sentiment scores for Galaxy S20 FE words
      S20FE_bing_count <- S20FE_words %>%
        inner_join(sentiments) %>%
        count(word, sentiment, sort = T) %>%
        mutate(word = reorder(word, n))

      # Plot sentiment scores for Galaxy S20FE words
      S20FE_bing_count %>% group_by(sentiment) %>%
        top_n(10) %>% ungroup() %>%
        ggplot(aes(x = word, y = n, fill = sentiment)) + theme_minimal() + coord_flip() +
          geom_col(show.legend = F) +
          facet_wrap(~ sentiment, scales = 'free_y') +
          labs(x = NULL, y = "Sentiment",
              title = "Most Common Positive and Negative Words in Galaxy S20 FE Tweets") +
          theme(axis.text = element_text(size = 11, colour = 'black'),
                axis.title = element_text(size = 11, colour = 'black'),
                title = element_text(size = 12))

END OF SLIDE


SLIDE START

  ##SENTIMENT DENSITY PLOTS ALL 3 IN 1 + ACTUAL KOLMOGOROV-SMIRNOV AND ANDERSON-DARLING TESTS

    REASON FOR REMOVAL
      Needed to be cut to save time and slide numbers

    SPEAKER NOTES
      We wanted to determine if there was a correlation between the stock price and the current sentiment of the public's opinion on Twitter.
      We decided to use a regression analysis to determine this and see if we could predict future stock price based on the current sentiment.7

    SLIDE INFO
      - Regression analysis used
      - P value = 

    CODE:
    feature_sentiment_data %>%
      ggplot(aes(x=avg_sentiment, group=product, fill=product)) +
      geom_density(adjust=1.5, alpha=.3) +
      theme_bw() +
      scale_fill_manual(values = c("Galaxy S20" = "turquoise",
                                  "Galaxy S20 FE" = "mediumpurple1",
                                  "iPhone12" = "lightgoldenrod3")) +
      labs(fill = "Product")

    s20fe_vals <- feature_sentiment_data %>% 
      filter(product=="Galaxy S20 FE") %>% .$avg_sentiment

    s20_vals <- feature_sentiment_data %>% 
      filter(product=="Galaxy S20") %>% .$avg_sentiment

    iphone12_vals <- feature_sentiment_data %>% 
      filter(product=="iPhone12") %>% .$avg_sentiment

    vals <- list(s20 = s20_vals, s20fe = s20fe_vals, iphone12 = iphone12_vals)


    #KOLMOGOROV-SMIRNOV normality test

    ks.test(x=vals$s20, y='pnorm')
    # data:  vals$s20
    # D = 0.40721, p-value < 2.2e-16
    # alternative hypothesis: two-sided

    ks.test(x=vals$s20fe, y='pnorm')
    # data:  vals$s20fe
    # D = 0.45695, p-value < 2.2e-16
    # alternative hypothesis: two-sided

    ks.test(x=vals$iphone12, y='pnorm')
    # data:  vals$iphone12
    # D = 0.40272, p-value < 2.2e-16
    # alternative hypothesis: two-sided

    #ANDERSON-DARLING normality test

    ad.test(vals$s20)
    # data:  vals$s20
    # A = 396.71, p-value < 2.2e-16

    ad.test(vals$s20fe)
    # data:  vals$s20fe
    # A = 660.69, p-value < 2.2e-16

    ad.test(vals$iphone12)
    # data:  vals$iphone12
    # A = 687.88, p-value < 2.2e-16

    #T-TEST JUST IN CASE
    t.test(vals$s20fe, vals$iphone12)
    t.test(vals$s20fe, vals$s20)

END OF SLIDE

SLIDE START

## Issues and overcoming them

  REASON FOR REMOVAL
    Most information is already in other slides so this seem redundant.

  SPEAKER NOTES
    Date refinement on Twitter Premium API functions only
      Dev suite allowed limited access to full archive and 30 day extraction features
    Tweets are pulled from date to backwards to date to
      Pull tweets in a controlled manner using weeks and days
    Possible duplication if we extracted at the same time
      Full archive and 30 day extraction allowed for refinement of dates and pull tweets back to 2006
    Extraction limited to 18k per 15mins
      Controlled pull of tweets with date refinement over time as retry on rate limit did not function a expected
    Foreign languages
      Filter by language of 'en' applied to only pull English tweets

  SLIDE INFO
    - Extraction by date
    - Duplication
    - Time limits
    - Foreign languages

END OF SLIDE

END OF ADDITIONAL/REMOVED SLIDES -->





<!--- Slide XX ------------------------------------------------------------------------------------------------------------->

## Improvements & Further Study

<!-- SPEAKER NOTES

  It would be useful to utilise the Google Maps API to have region filter on the tweets so we could focus the collection of data.


-->

**Improvements**

- Google Maps API 
- Look at mentions of apple in samsung and vice versa
- Examination of average income and sentiment by region
- Increased number of tweets with more targeted dates before and after the release dates

<!--- End of Slide XX ------------------------------------------------------------------------------------------------------>





<!--- Slide XX ------------------------------------------------------------------------------------------------------------->

## Conclusions

<!-- SPEAKER NOTES

-->

- Twitter data provides up to date information for companies to analyse customer feedback
- Data can provide useful information to guide product teams when analysed correctly
- With the world map data, which can be broken down into more specific regions, we can see key areas that need to have more targeted marketing or improve marketing to increase the sentiment


**Apple**




**Samsung**
BTS

<!--- End of Slide XX ------------------------------------------------------------------------------------------------------>





<!--- Slide XX ------------------------------------------------------------------------------------------------------------->

## References

- Ahmed, Wasim (2019). *Using Twitter as a data source: an overview of social media research tools* Available at: [https://blogs.lse.ac.uk/impactofsocialsciences/2019/06/18/using-twitter-as-a-data-source-an-overview-of-social-media-research-tools-2019/](https://blogs.lse.ac.uk/impactofsocialsciences/2019/06/18/using-twitter-as-a-data-source-an-overview-of-social-media-research-tools-2019/) (Accessed: 07 December 2020)

- Dalla Valle, Luciana (2020). *MATH513 Lecture and Tutorial Code* Available at: [https://dle.plymouth.ac.uk/course/view.php?id=49628](https://dle.plymouth.ac.uk/course/view.php?id=49628) (Accessed: 01 October 2020)

- Fuchs, Matti (2018) *Doing your first sentiment analysis in R with Sentimentr* Available at: [https://towardsdatascience.com/doing-your-first-sentiment-analysis-in-r-with-sentimentr-167855445132](https://towardsdatascience.com/doing-your-first-sentiment-analysis-in-r-with-sentimentr-167855445132) (Accessed: 06 December 2020)
  
- Rinker, Tyler (2020). *R Documentation - sentiment_by* Available at:  [https://www.rdocumentation.org/packages/sentimentr/versions/2.7.1/topics/sentiment_by](https://www.rdocumentation.org/packages/sentimentr/versions/2.7.1/topics/sentiment_by) (Accessed: 06 December 2020)

## References

- R Core Team (2020). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. Available at: [https://www.R-project.org/](https://www.R-project.org/)

- RStudio (2020). *R Markdown Cheat Sheet* Available at: [https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf](https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf) (Accessed: 10 October 2020)

- RStudio (2014). *R Markdown Reference Guide* Available at: [https://www.rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf](https://www.rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf) (Accessed: 10 October 2020)

- Twitter (2020). *API Documentation* Available at: [https://developer.twitter.com/en/docs/twitter-api](https://developer.twitter.com/en/docs/twitter-api) (Accessed: 10 October 2020)

- Young, Michelle (2017). *Twitter Data Mining: A Guide to Big Data Analytics Using Python* Available at: [https://chatbotslife.com/twitter-data-mining-a-guide-to-big-data-analytics-using-python-4efc8ccfa219](https://chatbotslife.com/twitter-data-mining-a-guide-to-big-data-analytics-using-python-4efc8ccfa219) (Accessed: 07 December 2020)

<!--- End of Slide XX ------------------------------------------------------------------------------------------------------>





<!-- END OF SLIDE SHOW -->